{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EycDv85kcDB"
      },
      "source": [
        "# Frontier Network Maintenance Detector\n",
        "## By Mark Friant and Keshav Santhanam\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stG1d2Kl8XEb"
      },
      "source": [
        "### Imports and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "8hTvs-BTwVNG"
      },
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd, torch, keras\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI9PMw2pwkzR",
        "outputId": "bd8356a3-81e3-41a3-bd81-9f3f551ef070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-210-75d6effb9bb1>:1: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_data = pd.read_csv(\"https://raw.githubusercontent.com/KeshavSanthanam/Hackathon2023/main/Data_Challenge/Data/training_data.csv\")\n"
          ]
        }
      ],
      "source": [
        "train_data = pd.read_csv(\"https://raw.githubusercontent.com/KeshavSanthanam/Hackathon2023/main/Data_Challenge/Data/training_data.csv\")\n",
        "test_data = pd.read_csv(\"https://raw.githubusercontent.com/KeshavSanthanam/Hackathon2023/main/Data_Challenge/Data/test_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt4SeIi9Adws"
      },
      "source": [
        "### Populating service_repair:\n",
        "Empty \"cells\" in a CSV file are considered as null in our dataframes, but that isn't a descriptive way to represent the lack of a repair when a repair is indicated by 1. We substitute the nulls with 0's to better represent the data, but this doesn't change our results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "hyY7AkVDkvuF"
      },
      "outputs": [],
      "source": [
        "# replace service_repair nulls with 0 (since no service repair occured)\n",
        "train_data['service_repair'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3ryhJj5-9wW"
      },
      "source": [
        "### Dropping REPORT_DATE\n",
        "REPORT_DATE is, by definition, a one-to-one match with each occurence of service_repair, and it obviously is not recorded in test_data, so it is essential that we remove it since it contains the \"answer\" to our model. We also drop 5 empty columns to limit the amount of processing power needed to develop our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "nhAj7iBcAdIm"
      },
      "outputs": [],
      "source": [
        "# remove REPORT_DATE\n",
        "train_data = train_data.drop('REPORT_DATE', axis=1)\n",
        "train_data = train_data.drop('Stops_null', axis=1)\n",
        "train_data = train_data.drop('Stops_NAS-Error', axis=1)\n",
        "train_data = train_data.drop('Stops_Port-Error', axis=1)\n",
        "train_data = train_data.drop('Stops_Service-Unavailable', axis=1)\n",
        "train_data = train_data.drop('Stops_User-Error', axis=1)\n",
        "\n",
        "test_data = test_data.drop('Stops_null', axis=1)\n",
        "test_data = test_data.drop('Stops_NAS-Error', axis=1)\n",
        "test_data = test_data.drop('Stops_Port-Error', axis=1)\n",
        "test_data = test_data.drop('Stops_Service-Unavailable', axis=1)\n",
        "test_data = test_data.drop('Stops_User-Error', axis=1)\n",
        "\n",
        "for col in test_data.columns:\n",
        "  if test_data[col].isnull().any():\n",
        "    test_data.drop(columns=col, inplace=True)\n",
        "    train_data.drop(columns=col, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmSzlcP3PTbe"
      },
      "source": [
        "### Our Sequential Neural Network\n",
        "We hash our strings to integers in order to use tensors and then construct a feedforward neural network with 60 nodes on input (to match the attributes) and a single output node to match the binary output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "7ny9CS-nNBXe"
      },
      "outputs": [],
      "source": [
        "train_feature_data = train_data.drop('service_repair', axis=1)\n",
        "train_label_data = train_data['service_repair']\n",
        "\n",
        "def sub_value(x):\n",
        "  if type(x) == str:\n",
        "    return 0 if x == '' else hash(x)\n",
        "  else:\n",
        "    return 0 if math.isnan(x) else x\n",
        "\n",
        "def my_hash(df):\n",
        "    for column in df.columns:\n",
        "      df[column] = df[column].apply(lambda x: sub_value(x))\n",
        "    return df\n",
        "\n",
        "train_feature_data = my_hash(train_feature_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrsy1wEmNSpD",
        "outputId": "0fbcdf6a-4379-4843-8a36-c067f99c6b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_39 (Dense)            (None, 60)                1440      \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 12)                732       \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2185 (8.54 KB)\n",
            "Trainable params: 2185 (8.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train_input, test_input, train_output, test_output = train_test_split(train_feature_data, train_label_data, test_size=0.2, random_state=42, shuffle=True)\n",
        "test_input, test_input2, test_output, test_output2 = train_test_split(test_input, test_output, test_size=0.5, random_state=42, shuffle=True)\n",
        "errors, accuracies = [], []\n",
        "errors2, accuracies2 = [], []\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(60, input_dim=train_feature_data.shape[1], activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=1)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'], run_eagerly=True)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8N60-FU0TVj",
        "outputId": "3ef5e008-27c4-4181-90fa-016529ba9935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1577/1577 [==============================] - 44s 28ms/step - loss: 7342599316701184.0000 - accuracy: 0.9589 - val_loss: 5889467462189056.0000 - val_accuracy: 0.9613\n",
            "Epoch 2/10\n",
            "1577/1577 [==============================] - 45s 29ms/step - loss: 3407641279725568.0000 - accuracy: 0.9582 - val_loss: 3896734438653952.0000 - val_accuracy: 0.9667\n",
            "Epoch 3/10\n",
            "1577/1577 [==============================] - 44s 28ms/step - loss: 2292039899152384.0000 - accuracy: 0.9583 - val_loss: 3236356641783808.0000 - val_accuracy: 0.9735\n",
            "Epoch 4/10\n",
            "1577/1577 [==============================] - 45s 28ms/step - loss: 1629023381749760.0000 - accuracy: 0.9585 - val_loss: 2130826691084288.0000 - val_accuracy: 0.9711\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(tf.convert_to_tensor(train_input.to_numpy()), tf.convert_to_tensor(train_output.to_numpy()), epochs=10, batch_size=32, initial_epoch=0, validation_data=(test_input, test_output), callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNEUVpBPm-Yl",
        "outputId": "6d8ad74e-d9f4-4f7a-e9c4-3aaf66a86c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198/198 [==============================] - 2s 12ms/step - loss: 2130826691084288.0000 - accuracy: 0.9711\n",
            "[0.9711431860923767]\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(test_input, test_output)\n",
        "errors.append(scores[0])\n",
        "accuracies.append(scores[1])\n",
        "print(accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNotrALC4eB0",
        "outputId": "8f52ad16-36c1-4c9c-c7dc-0802e5b24b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198/198 [==============================] - 3s 12ms/step - loss: 1787338963288064.0000 - accuracy: 0.9745\n",
            "[0.9744768738746643]\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(test_input2, test_output2)\n",
        "errors2.append(scores[0])\n",
        "accuracies2.append(scores[1])\n",
        "print(accuracies2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LPOex1bcmI8",
        "outputId": "9aa8c48c-9ae3-42cd-ce6d-8c2327c85a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1911/1911 [==============================] - 8s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "# prediction = model.predict(tf.convert_to_tensor(test_input.to_numpy()))\n",
        "\n",
        "test_data = my_hash(test_data)\n",
        "mp = model.predict(test_data)\n",
        "out_df = pd.DataFrame(mp)\n",
        "out_df.insert(0, \"Customer\", test_data['Customer'])\n",
        "out_df = out_df.rename(columns={out_df.columns[1]: 'Service_Repair'})\n",
        "out_df.to_csv('output.csv', index=False)\n",
        "\n",
        "# type(test_data['TSO_calls_count'][5])\n",
        "# math.isnan(test_data['TSO_calls_count'][5])\n",
        "#model.predict(test_data)\n",
        "  # print(model.predict(row.to_numpy()))\n",
        "\n",
        "# prediction = model.predict(test_input.to_numpy())\n",
        "\n",
        "# out_file = \"output.csv\"\n",
        "# out_df[0] = test_input.iloc[0]\n",
        "# out_df[1] = prediction\n",
        "# out_df = pd.DataFrame(out_np)\n",
        "\n",
        "# out_df.to_csv(out_file, sep=',')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}